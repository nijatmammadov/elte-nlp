{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install \"ultralytics<=8.3.40\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9m9gWX3KRpKF","executionInfo":{"status":"ok","timestamp":1750104011064,"user_tz":-120,"elapsed":114304,"user":{"displayName":"Random State","userId":"03272545008815056512"}},"outputId":"a5174896-a18a-4648-b733-af311695ea18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics<=8.3.40\n","  Downloading ultralytics-8.3.40-py3-none-any.whl.metadata (35 kB)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics<=8.3.40) (2.0.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics<=8.3.40) (3.10.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics<=8.3.40) (4.11.0.86)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics<=8.3.40) (11.2.1)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics<=8.3.40) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics<=8.3.40) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics<=8.3.40) (1.15.3)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics<=8.3.40) (2.6.0+cu124)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics<=8.3.40) (0.21.0+cu124)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics<=8.3.40) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics<=8.3.40) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics<=8.3.40) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics<=8.3.40) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics<=8.3.40) (0.13.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics<=8.3.40)\n","  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics<=8.3.40) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics<=8.3.40) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics<=8.3.40) (4.58.2)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics<=8.3.40) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics<=8.3.40) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics<=8.3.40) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics<=8.3.40) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics<=8.3.40) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics<=8.3.40) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics<=8.3.40) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics<=8.3.40) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics<=8.3.40) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics<=8.3.40) (2025.4.26)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics<=8.3.40) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics<=8.3.40) (4.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics<=8.3.40) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics<=8.3.40) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics<=8.3.40) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics<=8.3.40)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics<=8.3.40)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics<=8.3.40)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics<=8.3.40)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics<=8.3.40)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics<=8.3.40)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics<=8.3.40)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics<=8.3.40)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics<=8.3.40)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics<=8.3.40) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics<=8.3.40) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics<=8.3.40) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics<=8.3.40)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics<=8.3.40) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics<=8.3.40) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics<=8.3.40) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics<=8.3.40) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics<=8.3.40) (3.0.2)\n","Downloading ultralytics-8.3.40-py3-none-any.whl (898 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.5/898.5 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n","Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.40 ultralytics-thop-2.0.14\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7KDroMmmRxgu","executionInfo":{"status":"ok","timestamp":1750113761241,"user_tz":-120,"elapsed":2704,"user":{"displayName":"Random State","userId":"03272545008815056512"}},"outputId":"498d5726-42d4-49c6-ac65-c9b428fe9242"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"AimZ2qUV3Jz2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1 = pd.read_csv(\"/content/drive/MyDrive/nlp_project_elte/data1.csv\")\n","df2 = pd.read_csv(\"/content/drive/MyDrive/nlp_project_elte/data2.csv\")"],"metadata":{"id":"g_e7t6rvRkPD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.concat([df1,df2],axis=0)\n","df.drop(df.columns[0],axis = 1,inplace=True)"],"metadata":{"id":"fucNaE3oRn2_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"lu33WZ2VSXcp","executionInfo":{"status":"ok","timestamp":1750023456215,"user_tz":-120,"elapsed":109,"user":{"displayName":"Aemond Targaryen","userId":"01729535462368837740"}},"outputId":"f959a4ad-1c48-4dbe-fa6d-03f83cd16df0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              images  \\\n","0  /content/drive/MyDrive/nlp_project_elte/data/1...   \n","1  /content/drive/MyDrive/nlp_project_elte/data/1...   \n","2  /content/drive/MyDrive/nlp_project_elte/data/1...   \n","3  /content/drive/MyDrive/nlp_project_elte/data/1...   \n","4  /content/drive/MyDrive/nlp_project_elte/data/1...   \n","\n","                                        descriptions  \n","0  Vehicle Summary:\\nThe image shows a section of...  \n","1  This image shows a close-up view of a refriger...  \n","2  This image shows a close-up view of a vehicle ...  \n","3  Vehicle Summary:\\nThe image displays a semi-tr...  \n","4  Vehicle Summary:\\nThe image shows the rear sec...  "],"text/html":["\n","  <div id=\"df-d718aa73-98d0-4893-83fd-92c8141756cf\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>images</th>\n","      <th>descriptions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/content/drive/MyDrive/nlp_project_elte/data/1...</td>\n","      <td>Vehicle Summary:\\nThe image shows a section of...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/content/drive/MyDrive/nlp_project_elte/data/1...</td>\n","      <td>This image shows a close-up view of a refriger...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/content/drive/MyDrive/nlp_project_elte/data/1...</td>\n","      <td>This image shows a close-up view of a vehicle ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/content/drive/MyDrive/nlp_project_elte/data/1...</td>\n","      <td>Vehicle Summary:\\nThe image displays a semi-tr...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/content/drive/MyDrive/nlp_project_elte/data/1...</td>\n","      <td>Vehicle Summary:\\nThe image shows the rear sec...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d718aa73-98d0-4893-83fd-92c8141756cf')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d718aa73-98d0-4893-83fd-92c8141756cf button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d718aa73-98d0-4893-83fd-92c8141756cf');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-4abea812-3fd1-4c69-ab0d-8bcba2c9182f\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4abea812-3fd1-4c69-ab0d-8bcba2c9182f')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-4abea812-3fd1-4c69-ab0d-8bcba2c9182f button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 429,\n  \"fields\": [\n    {\n      \"column\": \"images\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 429,\n        \"samples\": [\n          \"/content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_135433_anonimized.jpg\",\n          \"/content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_105034_anonimized.jpg\",\n          \"/content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101131_anonimized.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"descriptions\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 429,\n        \"samples\": [\n          \"**Vehicle Summary:**\\nA white 2018 DAF XF 480FT tractor unit in average condition, showing signs of appropriate age and mileage.\\n\\n**Detailed Description:**\\nThe vehicle is a heavy-duty tractor unit with a white exterior. The paint appears consistent with normal wear for its usage and age. There are no visible major dents or damage, and the bodywork is intact. The windshield and other glass surfaces show no signs of cracks or chips. The tires seem generally used, reflecting the long-distance nature of its utilization. The vehicle\\u2019s odometer reads 439,014 km, aligning with accepted mileage records.\\n\\n**Condition Assessment:**\\nThe tractor unit is in averagely used condition with all structural elements intact. The engine runs smoothly, and the lighting and chassis are in good order. However, the suspension requires inspection. A service inspection is recommended due to the unknown vehicle history.\\n\\n**Market Price Estimation:**\\n- **Net Purchase Value:** 9,000,000 HUF\\n- **Net Sales Value:** 10,500,000 HUF\\nThese values reflect the current market for similar vehicles in Hungary.\\n\\n**Technical Commentary:**\\nThe DAF XF 480FT is equipped with a 12,902 cm\\u00b3 engine delivering 355 kW of power, meeting EURO 6 environmental standards. The automatic transmission and seating capacity of two make it suitable for long-distance hauling.\\n\\n**Suggested Applications:**\\nThis tractor unit is well-suited for long-haul transport, given its design and engine capacity. With its average condition, it can continue in commercial use, provided a thorough service inspection is completed.\",\n          \"Vehicle Summary:\\nThe image displays a tire from a Mercedes-Benz V 250 BlueTec L 4Matic, a luxury passenger van, with details provided confirming its excellent condition and careful maintenance.\\n\\nDetailed Description:\\nThe tire shown is a Michelin 245/45 R19, noted to be at 80% tread condition for both front and rear axles. The tire's sidewall inscriptions include treadwear, traction, and temperature ratings for assurance in performance. The wheel rim appears to be in good condition with no visible scratches or dents.\\n\\nCondition Assessment:\\nThe vehicle is in better-than-average condition given its age and mileage, with no depreciation factors noted. The technical systems, including the engine and transmission, are functioning appropriately, and comprehensive inspections have found no irregularities.\\n\\nMarket Price Estimation:\\n- Market Selling Price (incl. VAT): 17,853,150 HUF\\n- Market Purchase Price (incl. VAT): 16,017,150 HUF\\nThe vehicle holds a favorable position in the Hungarian secondary market due to its popularity and service network availability.\\n\\nTechnical Commentary:\\nThis vehicle is equipped with a robust 2,143 cm\\u00b3 engine producing 140 kW of power. The 4Matic designation indicates all-wheel drive capabilities, enhancing traction and stability.\\n\\nSuggested Applications:\\nSuitable for luxury personal transportation, business shuttle service, or VIP transport, thanks to its combination of comfort, performance, and reliability.\",\n          \"This image shows the interior roof section of a vehicle, specifically the backseat area. The features visible include:\\n\\n1. **Ceiling Light**: Positioned centrally on the interior roof.\\n2. **Grab Handles**: There are grab handles on both sides of the interior, typical for rear passenger convenience.\\n3. **Rear Headrest**: Part of a headrest is visible, indicating seats directly below.\\n4. **View Outside**: Through the window, part of a building and a parked vehicle can be seen, suggesting the car is either parked or in a stationary position.\\n\\nThe overall condition of the vehicle's interior appears to be clean and well-maintained.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["model = YOLO(\"/content/drive/MyDrive/nlp_project_elte/od/od/saved_model.pt\")\n","image_paths = df[\"images\"].tolist()\n","\n","\n","records = []\n","\n","\n","for img_path in tqdm(image_paths):\n","    try:\n","        result = model.predict(source=img_path, save=False, conf=0.4)[0]\n","\n","        bboxes = []\n","        for box in result.boxes:\n","            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n","            bboxes.append([x1, y1, x2, y2])\n","\n","        records.append({\n","            \"image_path\": img_path,\n","            \"bboxes\": bboxes\n","        })\n","\n","    except Exception as e:\n","        print(f\"Error processing {img_path}: {e}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0qKvEzb7fMKZ","executionInfo":{"status":"ok","timestamp":1750024116675,"user_tz":-120,"elapsed":34977,"user":{"displayName":"Aemond Targaryen","userId":"01729535462368837740"}},"outputId":"67bd34b1-420c-48d0-aa39-b472e048cd3e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/429 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103309_anonimized.jpg: 640x480 1 Automobile, 11.0ms\n","Speed: 5.1ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 1/429 [00:00<01:35,  4.49it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103312_anonimized.jpg: 480x640 2 Automobiles, 11.0ms\n","Speed: 4.6ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 2/429 [00:00<01:26,  4.93it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103323_anonimized.jpg: 480x640 1 Automobile, 10.6ms\n","Speed: 4.6ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 3/429 [00:00<01:26,  4.90it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103316_anonimized.jpg: 480x640 1 Automobile, 10.1ms\n","Speed: 4.8ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 4/429 [00:00<01:26,  4.91it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103326_anonimized.jpg: 480x640 1 Automobile, 11.1ms\n","Speed: 4.6ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 5/429 [00:01<01:30,  4.68it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103349_anonimized.jpg: 480x640 1 Automobile, 10.0ms\n","Speed: 4.7ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|▏         | 6/429 [00:01<01:26,  4.87it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103332_anonimized.jpg: 640x480 1 Automobile, 14.3ms\n","Speed: 4.6ms preprocess, 14.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n"]},{"output_type":"stream","name":"stderr","text":["\r  2%|▏         | 7/429 [00:01<01:27,  4.84it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103353_anonimized.jpg: 480x640 1 Automobile, 9.0ms\n","Speed: 3.2ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  2%|▏         | 8/429 [00:01<01:18,  5.38it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103421_anonimized.jpg: 640x480 1 Automobile, 7.6ms\n","Speed: 3.8ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n"]},{"output_type":"stream","name":"stderr","text":["\r  2%|▏         | 9/429 [00:01<01:10,  5.95it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103356_anonimized.jpg: 480x640 1 Automobile, 7.7ms\n","Speed: 3.2ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  2%|▏         | 10/429 [00:01<01:05,  6.42it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103345_anonimized.jpg: 480x640 1 Automobile, 7.0ms\n","Speed: 3.3ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  3%|▎         | 11/429 [00:01<01:04,  6.49it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103359_anonimized.jpg: 480x640 1 Automobile, 11.1ms\n","Speed: 4.8ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  3%|▎         | 12/429 [00:02<01:05,  6.36it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103436_anonimized.jpg: 480x640 1 Automobile, 8.7ms\n","Speed: 4.5ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  3%|▎         | 13/429 [00:02<01:10,  5.88it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103439_anonimized.jpg: 480x640 1 Automobile, 10.0ms\n","Speed: 4.5ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  3%|▎         | 14/429 [00:02<01:15,  5.51it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103424_anonimized.jpg: 480x640 1 Automobile, 8.5ms\n","Speed: 4.5ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  3%|▎         | 15/429 [00:02<01:14,  5.56it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103447_anonimized.jpg: 480x640 1 Automobile, 8.2ms\n","Speed: 4.5ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▎         | 16/429 [00:02<01:16,  5.42it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103442_anonimized.jpg: 480x640 1 Automobile, 12.7ms\n","Speed: 4.3ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 17/429 [00:03<01:15,  5.45it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103458_anonimized.jpg: 480x640 1 Automobile, 12.6ms\n","Speed: 4.5ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 18/429 [00:03<01:16,  5.37it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103451_anonimized.jpg: 480x640 1 Automobile, 13.3ms\n","Speed: 4.6ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 19/429 [00:03<01:16,  5.34it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103521_anonimized.jpg: 480x640 1 Automobile, 8.5ms\n","Speed: 5.0ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  5%|▍         | 20/429 [00:03<01:14,  5.49it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103518_anonimized.jpg: 640x480 1 Automobile, 9.2ms\n","Speed: 4.5ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n"]},{"output_type":"stream","name":"stderr","text":["\r  5%|▍         | 21/429 [00:03<01:11,  5.67it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103456_anonimized.jpg: 480x640 1 Automobile, 10.6ms\n","Speed: 4.7ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  5%|▌         | 22/429 [00:04<01:13,  5.57it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103454_anonimized.jpg: 480x640 1 Automobile, 8.3ms\n","Speed: 4.4ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  5%|▌         | 23/429 [00:04<01:15,  5.36it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103515_anonimized.jpg: 640x480 1 Automobile, 8.8ms\n","Speed: 4.5ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 24/429 [00:04<01:12,  5.56it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103547_anonimized.jpg: 480x640 1 Automobile, 8.9ms\n","Speed: 4.5ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 25/429 [00:04<01:11,  5.68it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/169883/20250405_103532_anonimized.jpg: 480x640 1 Automobile, 10.1ms\n","Speed: 4.5ms preprocess, 10.1ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 26/429 [00:04<01:11,  5.62it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104344_anonimized.jpg: 480x640 1 Automobile, 8.0ms\n","Speed: 3.7ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104341_anonimized.jpg: 640x480 1 Automobile, 8.4ms\n","Speed: 4.1ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104333_anonimized.jpg: 480x640 1 Automobile, 12.1ms\n","Speed: 5.9ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  7%|▋         | 29/429 [00:04<00:41,  9.56it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104335_anonimized.jpg: 480x640 3 Automobiles, 14.4ms\n","Speed: 4.2ms preprocess, 14.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104352_anonimized.jpg: 480x640 1 Automobile, 10.4ms\n","Speed: 6.1ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  7%|▋         | 31/429 [00:04<00:34, 11.46it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104425_1_anonimized.jpg: 480x640 1 Automobile, 11.7ms\n","Speed: 4.6ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104349_anonimized.jpg: 480x640 1 Automobile, 17.3ms\n","Speed: 4.3ms preprocess, 17.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 33/429 [00:05<00:31, 12.74it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104428_anonimized.jpg: 480x640 1 Automobile, 14.3ms\n","Speed: 4.7ms preprocess, 14.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104443_1_anonimized.jpg: 480x640 1 Automobile, 13.8ms\n","Speed: 4.5ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 35/429 [00:05<00:29, 13.25it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104415_anonimized.jpg: 480x640 1 Automobile, 14.5ms\n","Speed: 4.5ms preprocess, 14.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104448_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 2.8ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  9%|▊         | 37/429 [00:05<00:27, 14.15it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104454_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.7ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104446_anonimized.jpg: 480x640 1 Automobile, 6.3ms\n","Speed: 3.2ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104532_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.6ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r  9%|▉         | 40/429 [00:05<00:22, 17.58it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104523_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.6ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104519_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.7ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104544_1_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.6ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 43/429 [00:05<00:19, 20.11it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104534_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.6ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104554_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.6ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104619_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.8ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 11%|█         | 46/429 [00:05<00:17, 22.52it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104623_anonimized.jpg: 480x640 1 Automobile, 7.2ms\n","Speed: 2.6ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104714_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.7ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104631_anonimized.jpg: 480x640 1 Automobile, 6.3ms\n","Speed: 2.6ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 11%|█▏        | 49/429 [00:05<00:16, 23.10it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104715_anonimized.jpg: 480x640 1 Automobile, 7.5ms\n","Speed: 2.8ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104717_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.6ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104600_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.7ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 52/429 [00:05<00:15, 24.21it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104604_anonimized.jpg: 480x640 1 Automobile, 6.7ms\n","Speed: 2.7ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104639_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.6ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104700_anonimized.jpg: 480x640 1 Automobile, 6.3ms\n","Speed: 2.7ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 13%|█▎        | 55/429 [00:06<00:14, 25.74it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104730_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 2.8ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104725_anonimized.jpg: 480x640 1 Automobile, 6.3ms\n","Speed: 2.8ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104732_anonimized.jpg: 480x640 1 Automobile, 6.6ms\n","Speed: 2.7ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▎        | 58/429 [00:06<00:14, 26.29it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104727_1_anonimized.jpg: 480x640 1 Automobile, 8.1ms\n","Speed: 4.1ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104734_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.6ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104755_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.6ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 61/429 [00:06<00:14, 25.76it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104805_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 3.0ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104816_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.6ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104826_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.7ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 15%|█▍        | 64/429 [00:06<00:13, 26.85it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104854_1_anonimized.jpg: 480x640 1 Automobile, 6.3ms\n","Speed: 2.6ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104737_anonimized.jpg: 480x640 1 Automobile, 6.7ms\n","Speed: 2.8ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104821_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 2.7ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 67/429 [00:06<00:13, 26.99it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104812_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 2.6ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104936_anonimized.jpg: 480x640 1 Automobile, 6.3ms\n","Speed: 2.6ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104911_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.6ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▋        | 70/429 [00:06<00:13, 27.15it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104907_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.8ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104932_anonimized.jpg: 480x640 1 Automobile, 6.3ms\n","Speed: 2.6ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104918_anonimized.jpg: 480x640 1 Automobile, 6.3ms\n","Speed: 2.8ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 17%|█▋        | 73/429 [00:06<00:13, 26.78it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_105023_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.7ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104947_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.8ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_105034_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.7ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 76/429 [00:06<00:13, 26.99it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_104955_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.7ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_105002_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.6ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_105203_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.6ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 79/429 [00:06<00:13, 26.81it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_105149_anonimized.jpg: 480x640 1 Automobile, 6.7ms\n","Speed: 3.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_105152_anonimized.jpg: 480x640 1 Automobile, 8.0ms\n","Speed: 2.7ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_105147_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.8ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 19%|█▉        | 82/429 [00:07<00:12, 26.91it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_105327_1_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.7ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_105205_1_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.8ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_105208_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.7ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|█▉        | 85/429 [00:07<00:12, 26.53it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_105211_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 2.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_105322_anonimized.jpg: 480x640 1 Automobile, 6.8ms\n","Speed: 2.8ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_105349_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 2.7ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 21%|██        | 88/429 [00:07<00:13, 25.60it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133308_anonimized.jpg: 480x640 1 Automobile, 6.6ms\n","Speed: 3.5ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133319_anonimized.jpg: 480x640 2 Automobiles, 6.6ms\n","Speed: 3.2ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133327_anonimized.jpg: 480x640 1 Automobile, 6.7ms\n","Speed: 3.1ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 21%|██        | 91/429 [00:07<00:20, 16.16it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133336_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.0ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133333_anonimized.jpg: 480x640 3 Automobiles, 10.6ms\n","Speed: 3.2ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133442_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 3.1ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 94/429 [00:07<00:26, 12.50it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133314_anonimized.jpg: 480x640 2 Automobiles, 6.5ms\n","Speed: 3.1ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133412_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.1ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 96/429 [00:08<00:28, 11.75it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133446_anonimized.jpg: 480x640 1 Automobile, 7.4ms\n","Speed: 4.1ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133343_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.1ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 23%|██▎       | 98/429 [00:08<00:31, 10.58it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133448_anonimized.jpg: 480x640 1 Automobile, 6.8ms\n","Speed: 3.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133503_anonimized.jpg: 640x480 1 Automobile, 7.6ms\n","Speed: 3.3ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n"]},{"output_type":"stream","name":"stderr","text":["\r 23%|██▎       | 100/429 [00:08<00:33,  9.95it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133453_anonimized.jpg: 480x640 1 Automobile, 7.1ms\n","Speed: 3.1ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133511_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.1ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 102/429 [00:08<00:34,  9.38it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133542_anonimized.jpg: 480x640 1 Automobile, 6.3ms\n","Speed: 3.1ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133524_anonimized.jpg: 480x640 1 Automobile, 7.1ms\n","Speed: 3.2ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 104/429 [00:09<00:35,  9.04it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133545_anonimized.jpg: 480x640 1 Automobile, 6.9ms\n","Speed: 4.3ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 105/429 [00:09<00:37,  8.75it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133556_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 3.2ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▍       | 106/429 [00:09<00:37,  8.52it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133552_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.1ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▍       | 107/429 [00:09<00:38,  8.29it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133614_anonimized.jpg: 480x640 1 Automobile, 6.9ms\n","Speed: 3.1ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▌       | 108/429 [00:09<00:38,  8.33it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133654_1_anonimized.jpg: 480x640 1 Automobile, 6.8ms\n","Speed: 3.1ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133626_anonimized.jpg: 480x640 2 Automobiles, 6.5ms\n","Speed: 3.2ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 110/429 [00:09<00:37,  8.50it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133654_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.1ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133629_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 3.0ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 112/429 [00:10<00:34,  9.09it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133658_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 3.1ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▋       | 113/429 [00:10<00:35,  8.98it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133712_anonimized.jpg: 480x640 1 Automobile, 6.7ms\n","Speed: 3.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 27%|██▋       | 114/429 [00:10<00:37,  8.42it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133717_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.3ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 27%|██▋       | 115/429 [00:10<00:38,  8.26it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133721_anonimized.jpg: 480x640 1 Automobile, 6.7ms\n","Speed: 3.1ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 27%|██▋       | 116/429 [00:10<00:38,  8.16it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133723_anonimized.jpg: 480x640 1 Automobile, 6.8ms\n","Speed: 3.0ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 27%|██▋       | 117/429 [00:10<00:37,  8.41it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133727_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 3.2ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 118/429 [00:10<00:36,  8.41it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133759_anonimized.jpg: 640x480 1 Automobile, 7.2ms\n","Speed: 3.1ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 119/429 [00:10<00:35,  8.67it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133706_anonimized.jpg: 480x640 1 Automobile, 7.2ms\n","Speed: 3.1ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 120/429 [00:11<00:36,  8.43it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133900_anonimized.jpg: 480x640 1 Automobile, 7.2ms\n","Speed: 3.3ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133921_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.1ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 122/429 [00:11<00:31,  9.63it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133953_anonimized.jpg: 480x640 1 Automobile, 6.9ms\n","Speed: 4.3ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 29%|██▊       | 123/429 [00:11<00:32,  9.31it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_134014_anonimized.jpg: 480x640 1 Automobile, 6.9ms\n","Speed: 3.1ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133937_anonimized.jpg: 640x480 1 Automobile, 7.1ms\n","Speed: 3.2ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n"]},{"output_type":"stream","name":"stderr","text":["\r 29%|██▉       | 125/429 [00:11<00:31,  9.65it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_134028_anonimized.jpg: 480x640 1 Automobile, 7.1ms\n","Speed: 3.0ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 29%|██▉       | 126/429 [00:11<00:31,  9.72it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_134025_anonimized.jpg: 480x640 1 Automobile, 9.0ms\n","Speed: 3.0ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|██▉       | 127/429 [00:11<00:31,  9.62it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_134017_anonimized.jpg: 480x640 1 Automobile, 6.7ms\n","Speed: 3.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|██▉       | 128/429 [00:11<00:31,  9.59it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165671/IMG_20241112_133932_anonimized.jpg: 640x480 1 Automobile, 7.5ms\n","Speed: 3.1ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/CZ LOKO/20210714_154816_anonimized.jpg: 480x640 2 Automobiles, 7.0ms\n","Speed: 2.5ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 130/429 [00:11<00:25, 11.95it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/CZ LOKO/20210714_154803_anonimized.jpg: 480x640 1 Automobile, 6.3ms\n","Speed: 2.4ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/CZ LOKO/1_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.0ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/CZ LOKO/20210714_154923_anonimized.jpg: 480x640 1 Automobile, 7.8ms\n","Speed: 3.1ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/CZ LOKO/20210714_154801_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.4ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/CZ LOKO/20210714_154746_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.3ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 31%|███▏      | 135/429 [00:12<00:13, 21.32it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/CZ LOKO/20210714_154835_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.4ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/CZ LOKO/20210714_154920_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.3ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/CZ LOKO/20210714_154823_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 2.4ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/CZ LOKO/20210714_154914_anonimized.jpg: 480x640 1 Automobile, 6.3ms\n","Speed: 2.4ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/CZ LOKO/20210714_154930_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.2ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 33%|███▎      | 140/429 [00:12<00:10, 27.87it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/CZ LOKO/20210714_154906_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.4ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/CZ LOKO/20210714_154942_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.3ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/CZ LOKO/20210714_154958_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.3ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/CZ LOKO/20210714_154934_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 2.4ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/CZ LOKO/20210714_154950_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.4ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 145/429 [00:12<00:08, 32.54it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/CZ LOKO/20210714_155006_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 2.4ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/CZ LOKO/2_anonimized.jpg: 256x640 2 Automobiles, 13.0ms\n","Speed: 1.8ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 256, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/CZ LOKO/20210714_154953_anonimized.jpg: 480x640 1 Automobile, 6.7ms\n","Speed: 2.4ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162390/20240828_121502_anonimized.jpg: 480x640 2 Automobiles, 6.6ms\n","Speed: 3.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 35%|███▍      | 149/429 [00:12<00:10, 25.91it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162390/20240828_121510_anonimized.jpg: 480x640 2 Automobiles, 6.3ms\n","Speed: 3.2ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162390/20240828_121519_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.1ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162390/20240828_121514_anonimized.jpg: 480x640 1 Automobile, 6.7ms\n","Speed: 3.5ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 35%|███▌      | 152/429 [00:12<00:17, 15.57it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162390/20240828_121540_anonimized.jpg: 480x640 2 Automobiles, 6.7ms\n","Speed: 3.2ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162390/20240828_121551_anonimized.jpg: 480x640 1 Automobile, 6.7ms\n","Speed: 3.3ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162390/20240828_121545_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.2ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 155/429 [00:13<00:22, 11.91it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162390/20240828_121552_anonimized.jpg: 480x640 3 Automobiles, 7.0ms\n","Speed: 3.2ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162390/20240828_121556_anonimized.jpg: 480x640 2 Automobiles, 6.6ms\n","Speed: 3.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 37%|███▋      | 157/429 [00:13<00:24, 11.01it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162390/20240828_121615_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.1ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162390/20240828_121656_anonimized.jpg: 480x640 1 Automobile, 7.8ms\n","Speed: 3.4ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 37%|███▋      | 159/429 [00:13<00:26, 10.29it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162390/20240828_121824_anonimized.jpg: 480x640 1 Automobile, 6.8ms\n","Speed: 3.2ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162390/20240828_121703_anonimized.jpg: 480x640 2 Automobiles, 6.4ms\n","Speed: 3.1ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 161/429 [00:14<00:27,  9.92it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162390/20240828_121621_anonimized.jpg: 480x640 1 Automobile, 6.3ms\n","Speed: 3.1ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_100037_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 3.1ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 163/429 [00:14<00:26, 10.17it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_100033_anonimized.jpg: 480x640 1 Automobile, 6.8ms\n","Speed: 3.5ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_100943_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.1ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 165/429 [00:14<00:28,  9.34it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_100056_anonimized.jpg: 640x480 1 Automobile, 7.0ms\n","Speed: 3.2ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_100047_anonimized.jpg: 640x480 1 Automobile, 6.5ms\n","Speed: 3.2ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n"]},{"output_type":"stream","name":"stderr","text":["\r 39%|███▉      | 167/429 [00:14<00:28,  9.16it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101004_anonimized.jpg: 480x640 2 Automobiles, 7.2ms\n","Speed: 3.1ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 39%|███▉      | 168/429 [00:14<00:28,  9.06it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101008_anonimized.jpg: 480x640 1 Automobile, 6.8ms\n","Speed: 3.2ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 39%|███▉      | 169/429 [00:15<00:28,  8.97it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_100958_anonimized.jpg: 480x640 1 Automobile, 6.6ms\n","Speed: 3.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|███▉      | 170/429 [00:15<00:29,  8.69it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_100949_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.2ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|███▉      | 171/429 [00:15<00:30,  8.33it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101114_anonimized.jpg: 480x640 1 Automobile, 8.3ms\n","Speed: 3.0ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101119_anonimized.jpg: 480x640 1 Automobile, 13.2ms\n","Speed: 4.7ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 173/429 [00:15<00:32,  8.00it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101105_anonimized.jpg: 480x640 1 Automobile, 9.2ms\n","Speed: 4.5ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 41%|████      | 174/429 [00:15<00:34,  7.32it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101153_anonimized.jpg: 480x640 2 Automobiles, 10.3ms\n","Speed: 4.5ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 41%|████      | 175/429 [00:15<00:36,  6.92it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101128_anonimized.jpg: 480x640 1 Automobile, 8.1ms\n","Speed: 4.4ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 41%|████      | 176/429 [00:16<00:36,  6.95it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101137_anonimized.jpg: 480x640 1 Automobile, 8.0ms\n","Speed: 4.2ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 41%|████▏     | 177/429 [00:16<00:34,  7.21it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101131_anonimized.jpg: 480x640 1 Automobile, 7.9ms\n","Speed: 4.4ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 41%|████▏     | 178/429 [00:16<00:33,  7.51it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101227_anonimized.jpg: 480x640 1 Automobile, 12.9ms\n","Speed: 4.3ms preprocess, 12.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 179/429 [00:16<00:35,  7.01it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101134_anonimized.jpg: 480x640 1 Automobile, 13.8ms\n","Speed: 4.4ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 180/429 [00:16<00:36,  6.84it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101223_anonimized.jpg: 480x640 1 Automobile, 12.0ms\n","Speed: 6.2ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 181/429 [00:16<00:36,  6.82it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101220_anonimized.jpg: 480x640 1 Automobile, 8.8ms\n","Speed: 5.0ms preprocess, 8.8ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 182/429 [00:16<00:36,  6.74it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101207_anonimized.jpg: 480x640 1 Automobile, 8.7ms\n","Speed: 4.5ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 43%|████▎     | 183/429 [00:17<00:37,  6.49it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101308_anonimized.jpg: 480x640 1 Automobile, 8.6ms\n","Speed: 4.5ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 43%|████▎     | 184/429 [00:17<00:39,  6.23it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101318_anonimized.jpg: 480x640 1 Automobile, 8.7ms\n","Speed: 4.5ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 43%|████▎     | 185/429 [00:17<00:37,  6.53it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101231_anonimized.jpg: 480x640 1 Automobile, 8.0ms\n","Speed: 4.5ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 43%|████▎     | 186/429 [00:17<00:39,  6.09it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101313_anonimized.jpg: 480x640 1 Automobile, 8.1ms\n","Speed: 4.4ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▎     | 187/429 [00:17<00:40,  5.99it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101348_anonimized.jpg: 480x640 1 Automobile, 8.2ms\n","Speed: 4.3ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 188/429 [00:17<00:36,  6.56it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101332_anonimized.jpg: 480x640 1 Automobile, 8.2ms\n","Speed: 4.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 189/429 [00:17<00:33,  7.11it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101345_anonimized.jpg: 480x640 1 Automobile, 9.3ms\n","Speed: 4.4ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 190/429 [00:18<00:34,  6.83it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101324_anonimized.jpg: 480x640 1 Automobile, 12.0ms\n","Speed: 4.4ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 45%|████▍     | 191/429 [00:18<00:37,  6.37it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101353_anonimized.jpg: 640x480 1 Automobile, 12.8ms\n","Speed: 4.6ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n"]},{"output_type":"stream","name":"stderr","text":["\r 45%|████▍     | 192/429 [00:18<00:35,  6.60it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101415_anonimized.jpg: 480x640 1 Automobile, 13.0ms\n","Speed: 4.4ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 45%|████▍     | 193/429 [00:18<00:34,  6.85it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101357_anonimized.jpg: 480x640 1 Automobile, 9.7ms\n","Speed: 5.2ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 45%|████▌     | 194/429 [00:18<00:35,  6.70it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101342_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.2ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 45%|████▌     | 195/429 [00:18<00:31,  7.34it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_130931_anonimized.jpg: 480x640 1 Automobile, 6.8ms\n","Speed: 3.3ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 196/429 [00:18<00:32,  7.22it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_130924_anonimized.jpg: 480x640 2 Automobiles, 6.5ms\n","Speed: 3.3ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 197/429 [00:19<00:32,  7.10it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_130941_anonimized.jpg: 480x640 1 Automobile, 6.6ms\n","Speed: 3.2ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 198/429 [00:19<00:32,  7.02it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_131009_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 3.1ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▋     | 199/429 [00:19<00:31,  7.31it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_131000_anonimized.jpg: 480x640 1 Automobile, 6.7ms\n","Speed: 3.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 47%|████▋     | 200/429 [00:19<00:30,  7.54it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_130946_anonimized.jpg: 480x640 3 Automobiles, 6.5ms\n","Speed: 3.2ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 47%|████▋     | 201/429 [00:19<00:30,  7.48it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_130950_anonimized.jpg: 480x640 2 Automobiles, 6.5ms\n","Speed: 3.2ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 47%|████▋     | 202/429 [00:19<00:31,  7.27it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_131011_anonimized.jpg: 480x640 1 Automobile, 7.2ms\n","Speed: 3.1ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 47%|████▋     | 203/429 [00:19<00:29,  7.65it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_131014_anonimized.jpg: 480x640 1 Automobile, 6.9ms\n","Speed: 3.2ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 204/429 [00:20<00:29,  7.71it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_131106_anonimized.jpg: 480x640 1 Automobile, 6.7ms\n","Speed: 3.2ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 205/429 [00:20<00:28,  7.92it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_131111_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.1ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 206/429 [00:20<00:29,  7.63it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_131055_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 3.0ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 207/429 [00:20<00:28,  7.89it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_131031_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 3.0ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 208/429 [00:20<00:27,  8.08it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_131121_anonimized.jpg: 480x640 1 Automobile, 6.6ms\n","Speed: 3.0ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 49%|████▊     | 209/429 [00:20<00:28,  7.80it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_131136_anonimized.jpg: 480x640 1 Automobile, 8.7ms\n","Speed: 3.1ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 49%|████▉     | 210/429 [00:20<00:29,  7.35it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_131116_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.1ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 49%|████▉     | 211/429 [00:20<00:29,  7.46it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_131152_1_anonimized.jpg: 480x640 1 Automobile, 8.5ms\n","Speed: 3.1ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 49%|████▉     | 212/429 [00:21<00:29,  7.41it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_131155_anonimized.jpg: 480x640 1 Automobile, 7.3ms\n","Speed: 3.3ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|████▉     | 213/429 [00:21<00:28,  7.45it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_131159_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.1ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|████▉     | 214/429 [00:21<00:28,  7.54it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_131207_anonimized.jpg: 640x480 1 Automobile, 8.8ms\n","Speed: 3.3ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 215/429 [00:21<00:28,  7.62it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_131201_anonimized.jpg: 480x640 1 Automobile, 7.1ms\n","Speed: 3.2ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 216/429 [00:21<00:26,  7.96it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_131204_anonimized.jpg: 480x640 2 Automobiles, 6.4ms\n","Speed: 3.2ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 51%|█████     | 217/429 [00:21<00:27,  7.83it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_131444_anonimized.jpg: 640x480 1 Automobile, 7.5ms\n","Speed: 3.7ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n"]},{"output_type":"stream","name":"stderr","text":["\r 51%|█████     | 218/429 [00:21<00:25,  8.19it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_131449_anonimized.jpg: 480x640 1 Automobile, 7.1ms\n","Speed: 3.2ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 51%|█████     | 219/429 [00:21<00:25,  8.32it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_131359_anonimized.jpg: 480x640 1 Automobile, 6.7ms\n","Speed: 3.1ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 51%|█████▏    | 220/429 [00:22<00:24,  8.57it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165484/IMG_20241002_131426_anonimized.jpg: 480x640 1 Automobile, 6.8ms\n","Speed: 3.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120148_anonimized.jpg: 480x640 1 Automobile, 7.0ms\n","Speed: 2.5ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 222/429 [00:22<00:18, 11.11it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120156_anonimized.jpg: 480x640 2 Automobiles, 6.3ms\n","Speed: 4.0ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120240_anonimized.jpg: 480x640 1 Automobile, 6.3ms\n","Speed: 2.5ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120200_anonimized.jpg: 480x640 2 Automobiles, 6.4ms\n","Speed: 2.5ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120212_anonimized.jpg: 480x640 1 Automobile, 6.6ms\n","Speed: 2.5ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 53%|█████▎    | 226/429 [00:22<00:11, 17.99it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120220_anonimized.jpg: 480x640 2 Automobiles, 6.3ms\n","Speed: 2.6ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120306_anonimized.jpg: 640x480 1 Automobile, 7.1ms\n","Speed: 3.0ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120336_anonimized.jpg: 480x640 1 Automobile, 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120302_anonimized.jpg: 640x480 1 Automobile, 6.9ms\n","Speed: 2.7ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▎    | 230/429 [00:22<00:08, 22.75it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120331_anonimized.jpg: 480x640 1 Automobile, 7.0ms\n","Speed: 2.5ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120309_anonimized.jpg: 640x480 1 Automobile, 7.4ms\n","Speed: 2.7ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120433_anonimized.jpg: 480x640 2 Automobiles, 7.1ms\n","Speed: 2.4ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120357_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.6ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 55%|█████▍    | 234/429 [00:22<00:07, 25.18it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120418_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 2.5ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120526_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.5ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120400_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.5ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120445_anonimized.jpg: 480x640 1 Automobile, 6.3ms\n","Speed: 4.1ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 55%|█████▌    | 238/429 [00:22<00:06, 27.74it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120454_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.5ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120624_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 2.7ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120508_anonimized.jpg: 480x640 1 Automobile, 6.6ms\n","Speed: 2.5ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120600_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.7ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▋    | 242/429 [00:22<00:06, 29.56it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120605_anonimized.jpg: 480x640 1 Automobile, 9.2ms\n","Speed: 2.5ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120541_anonimized.jpg: 480x640 1 Automobile, 9.8ms\n","Speed: 3.1ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120617_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.8ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 57%|█████▋    | 245/429 [00:22<00:06, 29.31it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120529_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 2.9ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120638_anonimized.jpg: 480x640 1 Automobile, 7.1ms\n","Speed: 3.0ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120632_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 3.8ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120721_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.5ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 249/429 [00:23<00:05, 30.78it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120708_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.5ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120734_anonimized.jpg: 480x640 2 Automobiles, 6.3ms\n","Speed: 2.5ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120756_anonimized.jpg: 480x640 2 Automobiles, 6.2ms\n","Speed: 2.6ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120726_anonimized.jpg: 480x640 1 Automobile, 6.3ms\n","Speed: 2.6ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 59%|█████▉    | 253/429 [00:23<00:05, 32.43it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120812_anonimized.jpg: 480x640 2 Automobiles, 6.4ms\n","Speed: 2.7ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120740_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 2.5ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120700_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.5ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120852_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.5ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|█████▉    | 257/429 [00:23<00:05, 32.71it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120814_anonimized.jpg: 480x640 1 Automobile, 6.7ms\n","Speed: 2.6ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120831_anonimized.jpg: 480x640 (no detections), 6.5ms\n","Speed: 2.6ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120907_anonimized.jpg: 480x640 1 Automobile, 8.1ms\n","Speed: 2.6ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120915_anonimized.jpg: 480x640 1 Automobile, 6.8ms\n","Speed: 2.6ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 61%|██████    | 261/429 [00:23<00:05, 33.01it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120839_anonimized.jpg: 480x640 2 Automobiles, 6.6ms\n","Speed: 2.7ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120931_anonimized.jpg: 480x640 1 Automobile, 11.7ms\n","Speed: 3.0ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121038_anonimized.jpg: 480x640 1 Automobile, 14.8ms\n","Speed: 10.7ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121002_anonimized.jpg: 480x640 1 Automobile, 10.8ms\n","Speed: 4.0ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 265/429 [00:23<00:05, 30.14it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121024_anonimized.jpg: 480x640 1 Automobile, 6.8ms\n","Speed: 4.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120910_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.5ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121031_anonimized.jpg: 480x640 1 Automobile, 6.3ms\n","Speed: 2.5ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_120942_anonimized.jpg: 480x640 1 Automobile, 6.6ms\n","Speed: 2.5ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 63%|██████▎   | 269/429 [00:23<00:05, 31.33it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121252_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 2.6ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121047_anonimized.jpg: 480x640 1 Automobile, 6.7ms\n","Speed: 2.6ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121244_anonimized.jpg: 480x640 1 Automobile, 6.8ms\n","Speed: 2.6ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121346_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.5ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▎   | 273/429 [00:23<00:04, 32.01it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121237_anonimized.jpg: 480x640 1 Automobile, 7.3ms\n","Speed: 2.6ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121258_anonimized.jpg: 480x640 1 Automobile, 6.7ms\n","Speed: 2.5ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121322_anonimized.jpg: 480x640 1 Automobile, 8.6ms\n","Speed: 2.5ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121327_anonimized.jpg: 480x640 1 Automobile, 7.6ms\n","Speed: 2.5ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 65%|██████▍   | 277/429 [00:23<00:04, 32.29it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121356_anonimized.jpg: 480x640 1 Automobile, 12.5ms\n","Speed: 3.9ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121336_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.7ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121444_anonimized.jpg: 480x640 1 Automobile, 6.8ms\n","Speed: 2.8ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121430_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.5ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 281/429 [00:24<00:04, 31.60it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121413_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.5ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121617_anonimized.jpg: 480x640 1 Automobile, 6.3ms\n","Speed: 2.6ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121417_anonimized.jpg: 480x640 1 Automobile, 6.3ms\n","Speed: 2.6ms preprocess, 6.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121506_anonimized.jpg: 480x640 1 Automobile, 6.7ms\n","Speed: 2.6ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▋   | 285/429 [00:24<00:04, 31.91it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121622_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.7ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_122340_anonimized.jpg: 480x640 2 Automobiles, 6.2ms\n","Speed: 2.5ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121900_anonimized.jpg: 480x640 (no detections), 6.6ms\n","Speed: 2.6ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_121624_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 2.6ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 67%|██████▋   | 289/429 [00:24<00:04, 31.73it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_122334_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 2.6ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_122324_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 2.5ms preprocess, 6.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/159347/20250320_122346_anonimized.jpg: 480x640 (no detections), 6.5ms\n","Speed: 2.6ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162749/20241121_141654_anonimized.jpg: 480x640 1 Automobile, 6.7ms\n","Speed: 3.3ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 293/429 [00:24<00:05, 25.46it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162749/20241121_141700_anonimized.jpg: 480x640 1 Automobile, 6.9ms\n","Speed: 3.2ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162749/20241121_141703_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.2ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162749/20241121_141719_anonimized.jpg: 480x640 1 Automobile, 7.9ms\n","Speed: 3.4ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 69%|██████▉   | 296/429 [00:24<00:08, 16.35it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162749/20241121_141709_anonimized.jpg: 480x640 2 Automobiles, 6.6ms\n","Speed: 3.2ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162749/20241121_141910_anonimized.jpg: 480x640 1 Automobile, 6.6ms\n","Speed: 3.2ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162749/20241121_141919_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.2ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|██████▉   | 299/429 [00:25<00:09, 13.36it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162749/20241121_141731_anonimized.jpg: 480x640 1 Automobile, 6.9ms\n","Speed: 3.3ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162749/20241121_141725_anonimized.jpg: 480x640 1 Automobile, 6.7ms\n","Speed: 3.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 301/429 [00:25<00:10, 12.58it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162749/20241121_141714_anonimized.jpg: 480x640 1 Automobile, 6.7ms\n","Speed: 3.2ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162749/20241121_141845_anonimized.jpg: 480x640 1 Automobile, 6.8ms\n","Speed: 3.2ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 71%|███████   | 303/429 [00:25<00:11, 11.26it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162749/20241121_142100_anonimized.jpg: 640x480 1 Automobile, 7.3ms\n","Speed: 3.3ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162749/20241121_141937_anonimized.jpg: 480x640 1 Automobile, 9.4ms\n","Speed: 3.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 71%|███████   | 305/429 [00:25<00:11, 10.86it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162749/20241121_142110_anonimized.jpg: 640x480 1 Automobile, 8.2ms\n","Speed: 4.7ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/162749/20241121_141954_anonimized.jpg: 480x640 1 Automobile, 7.1ms\n","Speed: 3.2ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 307/429 [00:26<00:11, 10.20it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165968/20241121_141700_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.2ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165968/20241121_141719_anonimized.jpg: 480x640 1 Automobile, 6.6ms\n","Speed: 3.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 309/429 [00:26<00:12,  9.46it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165968/20241121_141703_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 3.2ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165968/20241121_141709_anonimized.jpg: 480x640 2 Automobiles, 6.4ms\n","Speed: 3.3ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 311/429 [00:26<00:13,  8.81it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165968/20241121_141654_anonimized.jpg: 480x640 1 Automobile, 6.6ms\n","Speed: 3.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 73%|███████▎  | 312/429 [00:26<00:13,  8.60it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165968/20241121_141725_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 3.1ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 73%|███████▎  | 313/429 [00:26<00:13,  8.70it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165968/20241121_141714_anonimized.jpg: 480x640 1 Automobile, 7.1ms\n","Speed: 3.4ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 73%|███████▎  | 314/429 [00:26<00:13,  8.41it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165968/20241121_141919_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.1ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 73%|███████▎  | 315/429 [00:27<00:13,  8.50it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165968/20241121_141731_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.3ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165968/20241121_141910_anonimized.jpg: 480x640 1 Automobile, 6.6ms\n","Speed: 3.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 317/429 [00:27<00:12,  9.27it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165968/20241121_141845_anonimized.jpg: 480x640 1 Automobile, 7.1ms\n","Speed: 3.1ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 318/429 [00:27<00:12,  9.20it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165968/20241121_142100_anonimized.jpg: 640x480 1 Automobile, 7.2ms\n","Speed: 3.2ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 319/429 [00:27<00:11,  9.27it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165968/20241121_142110_anonimized.jpg: 640x480 1 Automobile, 6.7ms\n","Speed: 3.3ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▍  | 320/429 [00:27<00:12,  8.82it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165968/20241121_141954_anonimized.jpg: 480x640 1 Automobile, 7.3ms\n","Speed: 3.2ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/165968/20241121_141937_anonimized.jpg: 480x640 1 Automobile, 6.6ms\n","Speed: 3.2ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▌  | 322/429 [00:27<00:11,  9.62it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_141625_anonimized.jpg: 480x640 1 Automobile, 9.6ms\n","Speed: 4.2ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_141647_anonimized.jpg: 480x640 1 Automobile, 8.1ms\n","Speed: 4.2ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_141610_anonimized.jpg: 480x640 3 Automobiles, 6.9ms\n","Speed: 2.7ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_141525_anonimized.jpg: 480x640 1 Automobile, 7.2ms\n","Speed: 3.0ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 326/429 [00:27<00:06, 15.51it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_141750_anonimized.jpg: 480x640 2 Automobiles, 6.5ms\n","Speed: 2.6ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_141716_anonimized.jpg: 480x640 1 Automobile, 6.3ms\n","Speed: 2.6ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_141704_anonimized.jpg: 480x640 1 Automobile, 7.4ms\n","Speed: 4.0ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_141714_1_anonimized.jpg: 480x640 1 Automobile, 13.6ms\n","Speed: 4.3ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 77%|███████▋  | 330/429 [00:28<00:04, 20.37it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_141546_anonimized.jpg: 480x640 1 Automobile, 14.4ms\n","Speed: 3.8ms preprocess, 14.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_141718_1_anonimized.jpg: 480x640 1 Automobile, 8.1ms\n","Speed: 3.9ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_141707_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.5ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_141910_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.9ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 334/429 [00:28<00:03, 23.97it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_141754_anonimized.jpg: 480x640 1 Automobile, 8.4ms\n","Speed: 3.3ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_141907_anonimized.jpg: 480x640 1 Automobile, 6.6ms\n","Speed: 2.4ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_141901_anonimized.jpg: 480x640 1 Automobile, 7.2ms\n","Speed: 2.7ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_141756_anonimized.jpg: 480x640 1 Automobile, 7.1ms\n","Speed: 2.9ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 79%|███████▉  | 338/429 [00:28<00:03, 27.66it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_141855_anonimized.jpg: 480x640 1 Automobile, 8.0ms\n","Speed: 4.5ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_141946_1_anonimized.jpg: 480x640 1 Automobile, 8.2ms\n","Speed: 4.5ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_141934_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 2.6ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142009_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 3.8ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|███████▉  | 342/429 [00:28<00:02, 30.11it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142022_anonimized.jpg: 480x640 1 Automobile, 8.2ms\n","Speed: 3.7ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142026_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.5ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142000_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 2.5ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_141932_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 3.2ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142127_1_anonimized.jpg: 480x640 1 Automobile, 7.8ms\n","Speed: 2.4ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 81%|████████  | 347/429 [00:28<00:02, 33.22it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_141949_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 3.9ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142051_anonimized.jpg: 480x640 1 Automobile, 6.8ms\n","Speed: 4.0ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142131_anonimized.jpg: 480x640 1 Automobile, 6.6ms\n","Speed: 2.5ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142043_anonimized.jpg: 480x640 1 Automobile, 6.7ms\n","Speed: 2.4ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 351/429 [00:28<00:02, 34.50it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142031_anonimized.jpg: 480x640 1 Automobile, 7.7ms\n","Speed: 3.7ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142136_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 2.5ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142140_anonimized.jpg: 480x640 1 Automobile, 6.1ms\n","Speed: 2.5ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142144_anonimized.jpg: 480x640 1 Automobile, 7.3ms\n","Speed: 2.6ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 83%|████████▎ | 355/429 [00:28<00:02, 35.22it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142227_anonimized.jpg: 480x640 1 Automobile, 13.4ms\n","Speed: 8.2ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142215_anonimized.jpg: 480x640 1 Automobile, 9.9ms\n","Speed: 3.5ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142206_1_anonimized.jpg: 480x640 1 Automobile, 10.0ms\n","Speed: 3.7ms preprocess, 10.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142244_anonimized.jpg: 480x640 1 Automobile, 11.9ms\n","Speed: 5.0ms preprocess, 11.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▎ | 359/429 [00:28<00:02, 32.09it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142247_anonimized.jpg: 480x640 1 Automobile, 15.0ms\n","Speed: 4.7ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142323_anonimized.jpg: 480x640 1 Automobile, 8.6ms\n","Speed: 5.7ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142356_1_anonimized.jpg: 480x640 1 Automobile, 8.8ms\n","Speed: 4.1ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142251_anonimized.jpg: 480x640 1 Automobile, 13.3ms\n","Speed: 3.8ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 85%|████████▍ | 363/429 [00:29<00:02, 31.36it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142152_anonimized.jpg: 480x640 1 Automobile, 8.5ms\n","Speed: 7.7ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142350_anonimized.jpg: 480x640 1 Automobile, 8.2ms\n","Speed: 3.7ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142256_anonimized.jpg: 480x640 1 Automobile, 11.9ms\n","Speed: 3.7ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142401_anonimized.jpg: 480x640 1 Automobile, 11.8ms\n","Speed: 5.0ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 367/429 [00:29<00:01, 31.47it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142444_anonimized.jpg: 480x640 1 Automobile, 12.9ms\n","Speed: 5.0ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142423_anonimized.jpg: 480x640 1 Automobile, 9.5ms\n","Speed: 3.7ms preprocess, 9.5ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142416_anonimized.jpg: 480x640 1 Automobile, 8.3ms\n","Speed: 3.7ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142435_anonimized.jpg: 480x640 1 Automobile, 8.7ms\n","Speed: 3.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▋ | 371/429 [00:29<00:01, 31.88it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142448_anonimized.jpg: 480x640 1 Automobile, 8.5ms\n","Speed: 3.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142539_anonimized.jpg: 480x640 1 Automobile, 7.6ms\n","Speed: 3.7ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142510_anonimized.jpg: 480x640 1 Automobile, 11.4ms\n","Speed: 8.3ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142531_anonimized.jpg: 480x640 1 Automobile, 11.1ms\n","Speed: 8.9ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 87%|████████▋ | 375/429 [00:29<00:01, 31.57it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142503_anonimized.jpg: 480x640 1 Automobile, 8.6ms\n","Speed: 3.7ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142527_1_anonimized.jpg: 480x640 1 Automobile, 8.4ms\n","Speed: 3.7ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142520_anonimized.jpg: 480x640 1 Automobile, 7.6ms\n","Speed: 3.3ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142648_anonimized.jpg: 480x640 1 Automobile, 9.4ms\n","Speed: 3.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 379/429 [00:29<00:01, 31.03it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142626_anonimized.jpg: 480x640 1 Automobile, 8.2ms\n","Speed: 3.6ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142603_anonimized.jpg: 480x640 1 Automobile, 8.0ms\n","Speed: 4.3ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142621_1_anonimized.jpg: 480x640 1 Automobile, 9.7ms\n","Speed: 3.7ms preprocess, 9.7ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142550_anonimized.jpg: 480x640 2 Automobiles, 8.9ms\n","Speed: 4.9ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 89%|████████▉ | 383/429 [00:29<00:01, 30.86it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142555_anonimized.jpg: 480x640 1 Automobile, 7.9ms\n","Speed: 3.7ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142901_anonimized.jpg: 480x640 1 Automobile, 9.6ms\n","Speed: 3.8ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142722_anonimized.jpg: 480x640 1 Automobile, 7.3ms\n","Speed: 3.7ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142619_anonimized.jpg: 480x640 1 Automobile, 8.8ms\n","Speed: 5.7ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 387/429 [00:29<00:01, 30.67it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142844_anonimized.jpg: 480x640 1 Automobile, 7.5ms\n","Speed: 3.8ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142728_anonimized.jpg: 480x640 2 Automobiles, 7.2ms\n","Speed: 3.6ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142800_anonimized.jpg: 480x640 1 Automobile, 7.9ms\n","Speed: 3.6ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142924_anonimized.jpg: 480x640 1 Automobile, 7.2ms\n","Speed: 6.6ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 91%|█████████ | 391/429 [00:29<00:01, 30.89it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142915_anonimized.jpg: 480x640 1 Automobile, 9.7ms\n","Speed: 3.7ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/158220/IMG_20240319_142747_anonimized.jpg: 480x640 1 Automobile, 7.9ms\n","Speed: 3.8ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_133853_anonimized.jpg: 640x480 1 Automobile, 11.2ms\n","Speed: 4.4ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_133904_anonimized.jpg: 640x480 1 Automobile, 9.8ms\n","Speed: 4.9ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 395/429 [00:30<00:01, 20.08it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_134737_anonimized.jpg: 480x640 2 Automobiles, 10.0ms\n","Speed: 4.6ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_134746_anonimized.jpg: 480x640 1 Automobile, 8.5ms\n","Speed: 4.4ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_134751_anonimized.jpg: 640x480 1 Automobile, 9.4ms\n","Speed: 4.5ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n"]},{"output_type":"stream","name":"stderr","text":["\r 93%|█████████▎| 398/429 [00:30<00:02, 12.87it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_134757_anonimized.jpg: 480x640 (no detections), 9.7ms\n","Speed: 4.5ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_134753_anonimized.jpg: 640x480 1 Automobile, 9.4ms\n","Speed: 4.6ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n"]},{"output_type":"stream","name":"stderr","text":["\r 93%|█████████▎| 400/429 [00:31<00:02, 10.78it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_134803_anonimized.jpg: 480x640 1 Automobile, 10.0ms\n","Speed: 5.0ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_134806_anonimized.jpg: 640x480 1 Automobile, 8.9ms\n","Speed: 4.6ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n"]},{"output_type":"stream","name":"stderr","text":["\r 94%|█████████▎| 402/429 [00:31<00:03,  8.78it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_134810_anonimized.jpg: 640x480 (no detections), 8.4ms\n","Speed: 4.6ms preprocess, 8.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_134837_anonimized.jpg: 480x640 1 Automobile, 12.1ms\n","Speed: 4.4ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 94%|█████████▍| 404/429 [00:31<00:03,  7.90it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_134824_anonimized.jpg: 640x480 1 Automobile, 9.3ms\n","Speed: 4.5ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_134820_anonimized.jpg: 480x640 1 Automobile, 12.8ms\n","Speed: 6.3ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 95%|█████████▍| 406/429 [00:32<00:03,  7.37it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_134851_anonimized.jpg: 480x640 1 Automobile, 17.9ms\n","Speed: 5.4ms preprocess, 17.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 95%|█████████▍| 407/429 [00:32<00:03,  6.93it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_134956_anonimized.jpg: 480x640 1 Automobile, 13.3ms\n","Speed: 4.4ms preprocess, 13.3ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 95%|█████████▌| 408/429 [00:32<00:03,  6.47it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_134934_anonimized.jpg: 480x640 1 Automobile, 6.6ms\n","Speed: 3.1ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_134854_anonimized.jpg: 640x480 1 Automobile, 7.1ms\n","Speed: 3.2ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▌| 410/429 [00:32<00:02,  7.39it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_134841_anonimized.jpg: 480x640 1 Automobile, 7.0ms\n","Speed: 3.0ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▌| 411/429 [00:32<00:02,  7.57it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_135011_anonimized.jpg: 480x640 1 Automobile, 6.2ms\n","Speed: 3.0ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▌| 412/429 [00:32<00:02,  7.86it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_135009_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.1ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▋| 413/429 [00:33<00:01,  8.02it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_135036_anonimized.jpg: 480x640 1 Automobile, 8.4ms\n","Speed: 3.2ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_135033_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 3.1ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 97%|█████████▋| 415/429 [00:33<00:01,  8.84it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_135013_anonimized.jpg: 480x640 1 Automobile, 6.8ms\n","Speed: 3.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 97%|█████████▋| 416/429 [00:33<00:01,  9.04it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_135045_anonimized.jpg: 480x640 1 Automobile, 7.4ms\n","Speed: 3.2ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 97%|█████████▋| 417/429 [00:33<00:01,  9.09it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_135151_anonimized.jpg: 480x640 1 Automobile, 7.1ms\n","Speed: 3.3ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 97%|█████████▋| 418/429 [00:33<00:01,  8.73it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_135312_anonimized.jpg: 480x640 1 Automobile, 6.4ms\n","Speed: 3.0ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 98%|█████████▊| 419/429 [00:33<00:01,  8.62it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_135442_anonimized.jpg: 480x640 2 Automobiles, 6.3ms\n","Speed: 3.0ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 98%|█████████▊| 420/429 [00:33<00:01,  8.66it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_135339_anonimized.jpg: 480x640 1 Automobile, 7.0ms\n","Speed: 3.0ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 98%|█████████▊| 421/429 [00:33<00:00,  8.68it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_135433_anonimized.jpg: 480x640 3 Automobiles, 6.6ms\n","Speed: 3.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 98%|█████████▊| 422/429 [00:34<00:00,  8.66it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_135326_anonimized.jpg: 480x640 1 Automobile, 6.8ms\n","Speed: 3.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 99%|█████████▊| 423/429 [00:34<00:00,  8.61it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_135148_anonimized.jpg: 480x640 1 Automobile, 6.9ms\n","Speed: 3.3ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 99%|█████████▉| 424/429 [00:34<00:00,  8.50it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_135500_anonimized.jpg: 480x640 1 Automobile, 11.8ms\n","Speed: 4.3ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 99%|█████████▉| 425/429 [00:34<00:00,  8.04it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_135507_anonimized.jpg: 480x640 1 Automobile, 6.8ms\n","Speed: 3.2ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r 99%|█████████▉| 426/429 [00:34<00:00,  7.88it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_135450_anonimized.jpg: 480x640 2 Automobiles, 6.4ms\n","Speed: 3.1ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\r100%|█████████▉| 427/429 [00:34<00:00,  7.89it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_135759_anonimized.jpg: 480x640 1 Automobile, 6.5ms\n","Speed: 3.0ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","image 1/1 /content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_135753_anonimized.jpg: 480x640 1 Automobile, 8.4ms\n","Speed: 3.4ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 429/429 [00:34<00:00, 12.29it/s]\n"]}]},{"cell_type":"code","source":["df_yolo_grouped = pd.DataFrame(records)\n","df_yolo_grouped.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"oi6BZ5Thisgh","executionInfo":{"status":"ok","timestamp":1750024138733,"user_tz":-120,"elapsed":40,"user":{"displayName":"Aemond Targaryen","userId":"01729535462368837740"}},"outputId":"8f852228-8266-400b-92ff-db597f908627"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                          image_path  \\\n","0  /content/drive/MyDrive/nlp_project_elte/data/1...   \n","1  /content/drive/MyDrive/nlp_project_elte/data/1...   \n","2  /content/drive/MyDrive/nlp_project_elte/data/1...   \n","3  /content/drive/MyDrive/nlp_project_elte/data/1...   \n","4  /content/drive/MyDrive/nlp_project_elte/data/1...   \n","\n","                                        bboxes  \n","0                         [[0, 0, 3060, 4050]]  \n","1  [[85, 1, 4037, 3049], [243, 5, 2806, 3037]]  \n","2                         [[4, 0, 4077, 3060]]  \n","3                         [[0, 2, 4074, 2606]]  \n","4                         [[0, 0, 4078, 2586]]  "],"text/html":["\n","  <div id=\"df-d22fddcc-0cfa-4214-9978-3015d9693be2\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_path</th>\n","      <th>bboxes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/content/drive/MyDrive/nlp_project_elte/data/1...</td>\n","      <td>[[0, 0, 3060, 4050]]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/content/drive/MyDrive/nlp_project_elte/data/1...</td>\n","      <td>[[85, 1, 4037, 3049], [243, 5, 2806, 3037]]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/content/drive/MyDrive/nlp_project_elte/data/1...</td>\n","      <td>[[4, 0, 4077, 3060]]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/content/drive/MyDrive/nlp_project_elte/data/1...</td>\n","      <td>[[0, 2, 4074, 2606]]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/content/drive/MyDrive/nlp_project_elte/data/1...</td>\n","      <td>[[0, 0, 4078, 2586]]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d22fddcc-0cfa-4214-9978-3015d9693be2')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d22fddcc-0cfa-4214-9978-3015d9693be2 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d22fddcc-0cfa-4214-9978-3015d9693be2');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-ad53c1c6-6da9-4365-b471-5c90dff4ee86\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ad53c1c6-6da9-4365-b471-5c90dff4ee86')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-ad53c1c6-6da9-4365-b471-5c90dff4ee86 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_yolo_grouped","summary":"{\n  \"name\": \"df_yolo_grouped\",\n  \"rows\": 429,\n  \"fields\": [\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 429,\n        \"samples\": [\n          \"/content/drive/MyDrive/nlp_project_elte/data/157515_v2/IMG_20240402_135433_anonimized.jpg\",\n          \"/content/drive/MyDrive/nlp_project_elte/data/161552_v2/IMG_20240720_105034_anonimized.jpg\",\n          \"/content/drive/MyDrive/nlp_project_elte/data/165720/IMG_20241118_101131_anonimized.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bboxes\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["# Merge or join based on image_path\n","df_merged = df_yolo_grouped.merge(df[['images', 'descriptions']], left_on='image_path', right_on='images', how='left')\n"],"metadata":{"id":"Sp-FPvdGk11N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_merged.drop('images',inplace=True,axis=1)"],"metadata":{"id":"ARPDjYRuk0wb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_merged = pd.read_csv(\"/content/drive/MyDrive/nlp_project_elte/df_merged.csv\")"],"metadata":{"id":"ai7ec-RxPCQl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HIRR_t9O2Exv"},"execution_count":null,"outputs":[]}]}